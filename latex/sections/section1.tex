Retrieval-Augmented Generation (RAG) systems have transformed numerous knowledge-intensive applications such as open-domain question answering, summarization, and dialogue systems by integrating information retrieval mechanisms with text generation models. Unlike stand-alone generative systems, RAG pipelines rely on retrieving relevant external knowledge to guide the generative process, making its outputs more accurate, contextually aware, and factually grounded.

The backbone of RAG systems is embedding models, which represent textual, visual, or multi-modal data in dense vector spaces. In recent years, the transition from static embeddings (e.g., word2vec, GloVe) to contextual embeddings powered by transformer architectures (e.g., BERT, T5, and GPT) has revolutionized information retrieval and natural language generation. These contextual embeddings serve as the foundation for both retrieval and generation stages in RAG.

The remainder of this literature review is structured as follows. In Section ~\ref{sec:embeddings}, I provide a detailed categorization of embedding techniques used in retrieval stage in RAG pipelines, including encoder-only, encoder-decoder, decoder-only, and multi-modal embeddings, while highlighting their respective applications in retrieval, generation, and RAG systems. Section~\ref{sec:enhancing} explores strategies to enhance embedding models. Section~\ref{sec:benchmarks} discusses existing benchmarks, such as the Massive Text Embedding Benchmark (MTEB), and evaluates their ability to measure the effectiveness of embedding models for RAG. 
Section~\ref{sec:conclusion} concludes by summarizing the critical role of embeddings in RAG systems and the opportunities for future advancements in the field.
